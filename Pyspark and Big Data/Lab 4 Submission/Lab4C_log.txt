/storage/icds/RISE/sw8/spark-3.3.0-bin-hadoop3/sbin/start-master.sh
starting org.apache.spark.deploy.master.Master, logging to /storage/work/ljc5809/Lab4/spark-ljc5809-org.apache.spark.deploy.master.Master-1-p-bc-5019.out
/storage/icds/RISE/sw8/spark-3.3.0-bin-hadoop3/bin/spark-class org.apache.spark.deploy.worker.Worker --work-dir /storage/work/ljc5809/Lab4 spark://p-bc-5019:7077
Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties
25/02/05 15:29:27 INFO Worker: Started daemon with process name: 2791871@p-bc-5019
25/02/05 15:29:27 INFO SignalUtils: Registering signal handler for TERM
25/02/05 15:29:27 INFO SignalUtils: Registering signal handler for HUP
25/02/05 15:29:27 INFO SignalUtils: Registering signal handler for INT
25/02/05 15:29:28 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
25/02/05 15:29:28 INFO SecurityManager: Changing view acls to: ljc5809
25/02/05 15:29:28 INFO SecurityManager: Changing modify acls to: ljc5809
25/02/05 15:29:28 INFO SecurityManager: Changing view acls groups to: 
25/02/05 15:29:28 INFO SecurityManager: Changing modify acls groups to: 
25/02/05 15:29:28 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(ljc5809); groups with view permissions: Set(); users  with modify permissions: Set(ljc5809); groups with modify permissions: Set()
25/02/05 15:29:28 INFO Utils: Successfully started service 'sparkWorker' on port 39949.
25/02/05 15:29:28 INFO Worker: Worker decommissioning not enabled.
25/02/05 15:29:29 INFO Worker: Starting Spark worker 10.6.8.29:39949 with 2 cores, 7.0 GiB RAM
25/02/05 15:29:29 INFO Worker: Running Spark version 3.3.0
25/02/05 15:29:29 INFO Worker: Spark home: /storage/icds/RISE/sw8/spark-3.3.0-bin-hadoop3
25/02/05 15:29:29 INFO ResourceUtils: ==============================================================
25/02/05 15:29:29 INFO ResourceUtils: No custom resources configured for spark.worker.
25/02/05 15:29:29 INFO ResourceUtils: ==============================================================
25/02/05 15:29:29 INFO Utils: Successfully started service 'WorkerUI' on port 8081.
25/02/05 15:29:29 INFO WorkerWebUI: Bound WorkerWebUI to 0.0.0.0, and started at http://p-bc-5019.2e.hpc.psu.edu:8081
25/02/05 15:29:29 INFO Worker: Connecting to master p-bc-5019:7077...
25/02/05 15:29:29 INFO TransportClientFactory: Successfully created connection to p-bc-5019/10.6.8.29:7077 after 59 ms (0 ms spent in bootstraps)
25/02/05 15:29:30 INFO Worker: Successfully registered with master spark://p-bc-5019:7077
25/02/05 15:29:41 INFO SparkContext: Running Spark version 3.3.0
25/02/05 15:29:41 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
25/02/05 15:29:41 INFO ResourceUtils: ==============================================================
25/02/05 15:29:41 INFO ResourceUtils: No custom resources configured for spark.driver.
25/02/05 15:29:41 INFO ResourceUtils: ==============================================================
25/02/05 15:29:41 INFO SparkContext: Submitted application: Lab4 BMB hastag changes
25/02/05 15:29:42 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
25/02/05 15:29:42 INFO ResourceProfile: Limiting resource is cpu
25/02/05 15:29:42 INFO ResourceProfileManager: Added ResourceProfile id: 0
25/02/05 15:29:42 INFO SecurityManager: Changing view acls to: ljc5809
25/02/05 15:29:42 INFO SecurityManager: Changing modify acls to: ljc5809
25/02/05 15:29:42 INFO SecurityManager: Changing view acls groups to: 
25/02/05 15:29:42 INFO SecurityManager: Changing modify acls groups to: 
25/02/05 15:29:42 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(ljc5809); groups with view permissions: Set(); users  with modify permissions: Set(ljc5809); groups with modify permissions: Set()
25/02/05 15:29:42 INFO Utils: Successfully started service 'sparkDriver' on port 34311.
25/02/05 15:29:42 INFO SparkEnv: Registering MapOutputTracker
25/02/05 15:29:42 INFO SparkEnv: Registering BlockManagerMaster
25/02/05 15:29:42 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
25/02/05 15:29:42 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
25/02/05 15:29:42 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
25/02/05 15:29:42 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-8c465673-8d58-4730-9972-aeab2cc69dff
25/02/05 15:29:42 INFO MemoryStore: MemoryStore started with capacity 434.4 MiB
25/02/05 15:29:42 INFO SparkEnv: Registering OutputCommitCoordinator
25/02/05 15:29:43 INFO Utils: Successfully started service 'SparkUI' on port 4040.
25/02/05 15:29:43 INFO StandaloneAppClient$ClientEndpoint: Connecting to master spark://p-bc-5019:7077...
25/02/05 15:29:43 INFO TransportClientFactory: Successfully created connection to p-bc-5019/10.6.8.29:7077 after 41 ms (0 ms spent in bootstraps)
25/02/05 15:29:43 INFO StandaloneSchedulerBackend: Connected to Spark cluster with app ID app-20250205152943-0000
25/02/05 15:29:43 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 42117.
25/02/05 15:29:43 INFO NettyBlockTransferService: Server created on p-bc-5019.2e.hpc.psu.edu:42117
25/02/05 15:29:43 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
25/02/05 15:29:43 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, p-bc-5019.2e.hpc.psu.edu, 42117, None)
25/02/05 15:29:43 INFO BlockManagerMasterEndpoint: Registering block manager p-bc-5019.2e.hpc.psu.edu:42117 with 434.4 MiB RAM, BlockManagerId(driver, p-bc-5019.2e.hpc.psu.edu, 42117, None)
25/02/05 15:29:43 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, p-bc-5019.2e.hpc.psu.edu, 42117, None)
25/02/05 15:29:43 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, p-bc-5019.2e.hpc.psu.edu, 42117, None)
25/02/05 15:29:43 INFO StandaloneAppClient$ClientEndpoint: Executor added: app-20250205152943-0000/0 on worker-20250205152929-10.6.8.29-39949 (10.6.8.29:39949) with 2 core(s)
25/02/05 15:29:43 INFO Worker: Asked to launch executor app-20250205152943-0000/0 for Lab4 BMB hastag changes
25/02/05 15:29:43 INFO StandaloneSchedulerBackend: Granted executor ID app-20250205152943-0000/0 on hostPort 10.6.8.29:39949 with 2 core(s), 1024.0 MiB RAM
25/02/05 15:29:43 INFO SecurityManager: Changing view acls to: ljc5809
25/02/05 15:29:43 INFO SecurityManager: Changing modify acls to: ljc5809
25/02/05 15:29:43 INFO SecurityManager: Changing view acls groups to: 
25/02/05 15:29:43 INFO SecurityManager: Changing modify acls groups to: 
25/02/05 15:29:43 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(ljc5809); groups with view permissions: Set(); users  with modify permissions: Set(ljc5809); groups with modify permissions: Set()
25/02/05 15:29:44 INFO ExecutorRunner: Launch command: "/usr/lib/jvm/java-11-openjdk-11.0.25.0.9-2.el8.x86_64/bin/java" "-cp" "/storage/icds/RISE/sw8/spark-3.3.0-bin-hadoop3/conf/:/storage/icds/RISE/sw8/spark-3.3.0-bin-hadoop3/jars/*" "-Xmx1024M" "-Dspark.driver.port=34311" "-XX:+IgnoreUnrecognizedVMOptions" "--add-opens=java.base/java.lang=ALL-UNNAMED" "--add-opens=java.base/java.lang.invoke=ALL-UNNAMED" "--add-opens=java.base/java.lang.reflect=ALL-UNNAMED" "--add-opens=java.base/java.io=ALL-UNNAMED" "--add-opens=java.base/java.net=ALL-UNNAMED" "--add-opens=java.base/java.nio=ALL-UNNAMED" "--add-opens=java.base/java.util=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent=ALL-UNNAMED" "--add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED" "--add-opens=java.base/sun.nio.ch=ALL-UNNAMED" "--add-opens=java.base/sun.nio.cs=ALL-UNNAMED" "--add-opens=java.base/sun.security.action=ALL-UNNAMED" "--add-opens=java.base/sun.util.calendar=ALL-UNNAMED" "--add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED" "org.apache.spark.executor.CoarseGrainedExecutorBackend" "--driver-url" "spark://CoarseGrainedScheduler@p-bc-5019.2e.hpc.psu.edu:34311" "--executor-id" "0" "--hostname" "10.6.8.29" "--cores" "2" "--app-id" "app-20250205152943-0000" "--worker-url" "spark://Worker@10.6.8.29:39949"
25/02/05 15:29:44 INFO StandaloneAppClient$ClientEndpoint: Executor updated: app-20250205152943-0000/0 is now RUNNING
25/02/05 15:29:44 INFO StandaloneSchedulerBackend: SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
25/02/05 15:30:04 INFO Worker: Asked to kill executor app-20250205152943-0000/0
25/02/05 15:30:04 INFO ExecutorRunner: Runner thread for executor app-20250205152943-0000/0 interrupted
25/02/05 15:30:04 INFO ExecutorRunner: Killing process!
25/02/05 15:30:04 INFO Worker: Executor app-20250205152943-0000/0 finished with state KILLED exitStatus 143
25/02/05 15:30:04 INFO ExternalShuffleBlockResolver: Clean up non-shuffle and non-RDD files associated with the finished executor 0
25/02/05 15:30:04 INFO ExternalShuffleBlockResolver: Executor is not registered (appId=app-20250205152943-0000, execId=0)
25/02/05 15:30:04 INFO ExternalShuffleBlockResolver: Application app-20250205152943-0000 removed, cleanupLocalDirs = true
25/02/05 15:30:04 INFO Worker: Cleaning up local directories for application app-20250205152943-0000
SPARK_MASTER_HOST=p-bc-5019
SPARK_MASTER_PORT=7077

real	0m47.163s
user	0m17.795s
sys	0m1.177s
