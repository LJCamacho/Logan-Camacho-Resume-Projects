---
title: "STAT380_HW9"
author: Name
output: html_document
date: "Due: Due on Thursday, April 24, 2025 by 11:59 PM)"
---

## Instructions

In class, we introduced 3 methods for selecting the features to be included in a model (forward, backward, LASSO). The activities that follow are meant to provide further practice with these concepts. NOTE: All required `library` commands **must be** included in the Front Matter section. If you include your `library` commands elsewhere in your code, you will be penalized.

At the conclusion to the activity, you should upload

1.  your .html file named LastnameFirstInitial_STAT380_HW9.html
2.  your .Rmd file named LastnameFirstInitial_STAT380_HW9.Rmd

## Learning Objectives
This assignment address aspects of the following learning objectives.

1. Students will be able to load datasets from R packages and external sources into the R environment.
2. Given a statistical learning method, students will be able to restructure the data for use in the corresponding R function.
3.	Identify the best subset of predictors for a linear regression model using subset selection methods, such as best subsets or stepwise regression, using statistical software.
4. Apply shrinkage/regularization methods for estimating parameters using statistical software, including selecting a value for the tuning parameter using cross validation.
5. Interpret the results of LASSO in the context of feature selection.
6. Compare the ability of competing models to generalize for new data.


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Front Matter - Clean Environment, Load Libraries, User Defined Functions

```{r}
rm(list = ls())
#Add libraries as needed
library(tidyverse)
library(glmnet) #To perform LASSO and Ridge
library(rpart) #For regression and classification trees
library(rattle) #For nice visualization of trees

#Read in dataset
MLB <- read.csv("C:/Users/Blungus/OneDrive - The Pennsylvania State University/2024-25/Spring Sem/Stat 380/Test CSV files/MLB.csv")
```


## Problem 1. Baseball Data 

`MLB.csv` contains information about a sample of Major League Baseball (MLB) players from the 1986 and 1987 seasons. Variables include:

* PlayerName-Player’s name
* AtBat-Number of times at bat in 1986
* Hits-Number of hits in 1986
* HmRun-Number of home runs in 1986
* Runs-Number of runs in 1986
* RBI-Number of runs batted in in 1986
* Walks-Number of walks in 1986
* Years-Number of years in the major leagues
* CAtBat-Number of times at bat during his career
* Chits-Number of hits during his career
* CHmRun-Number of home runs during his career
* CRuns-Number of runs during his career
* CRBI-Number of runs batted in during his career
* CWalks-Number of walks during his career
* League-factor with levels A (for American) and N (for National) indicating player's league at the end of 1986
* Division-factor with levels E (for East) and W (for West) indicating player's division at the end of 1986
* PutOuts-Number of put outs in 1986
* Assists-Number of assists in 1986
* Errors-Number of errors in 1986
* Salary-1987 annual salary on opening day in thousands of dollars
* NewLeague-factor with levels A (for American) and N (for National) indicating player's league at the beginning of 1987

**Our goal is to predict a baseball player’s 1987 salary on the basis of the other variables in the dataset (excluding player name).**

a. Remove the `PlayerName` column and any players with a missing salary. Name the result `MLB2`. NOTE: `MLB2` should have 263 observations and 20 variables.
```{r}
MLB2 <- MLB %>%
  select(-PlayerName) %>%
  filter(!is.na(Salary))
  


```


b. In order to use the `glmnet` and/or `cv.glmnet` function for building LASSO regression models, create the input matrix and response variable vector. 

```{r}
#Create input matrix and response vector
Xmat <- model.matrix(Salary ~ ., data = MLB2)[, -1]
yvec <- MLB2$Salary


```


c. Using a seed of 321, perform an 85/15 training/validation split.
```{r}
#Perform 80/20 training/validation split using seed of 321
set.seed(321)
trainInd <- sample(1:nrow(MLB2), floor(0.85*nrow(MLB2)))
set.seed(NULL)

#Split Xmat and yvec separately
XmatTrain <- Xmat[trainInd, ]
XmatValidation <- Xmat[-trainInd, ]

yvecTrain <- yvec[trainInd]
yvecValidation <- yvec[-trainInd]

```




d. Using a seed of 12345 and 10-fold cross validation on the training data, use the `cv.glmnet` function to create the plot of MSE as a function of $log(\lambda)$. NOTE: The seed mentioned in this problem should not be used to repeat the training/validation split. Instead, it is the seed for the `cv.glmnet` function which will do the 10-fold cross validation for you.

```{r}
#Use 10-fold CV to pick lambda for LASSO (use seed 123)
set.seed(12345)
lassoCV <- cv.glmnet(x = XmatTrain,
                     y = yvecTrain,
                     family = "gaussian",
                     alpha = 1,
                     lambda = NULL,
                     standardize = TRUE,
                     nfolds = 10)
set.seed(NULL)
#Show the LASSO CV results
plot(lassoCV)

```



e. What is the optimal $\lambda$ for LASSO regression based on using the minimum value of MSE rule? Which variables are included using this value of $\lambda$? 

f. What is the optimal $\lambda$ for LASSO regression based on using the 1-standard error (1SE) rule? Which variables are included using this value of $\lambda$? 

```{r}
#Display the optimal values of lambda
lassoCV$lambda.min
lassoCV$lambda.1se


#Store the coefficients associated with the optimal values
coefLamMin <- predict(lassoCV, s = lassoCV$lambda.min, type = "coefficients")
coefLam1se <- predict(lassoCV, s = lassoCV$lambda.1se, type = "coefficients")

#Create a data frame for comparing the coefficients
tempdf <- 
  data.frame(Variable = row.names(coefLamMin), 
             lamMin = as.numeric(coefLamMin), 
             lam1se = as.numeric(coefLam1se))

tempdf
```

Using the minimum MSE rule, all variables are included except for 'RBI', 'CAtBat', and 'CHits'.

Using the 1-standard error rule, the only variables **included** were 'Hits' and 'Walks'




g. Using the value of $\lambda$ associated with the minimum MSE, compute **and interpret** the RMSE on validation data.

```{r}
#LASSO
lassoYhat <- predict(lassoCV,
                     s = lassoCV$lambda.min,
                     newx = XmatValidation)
  
  
  
lassoMSE <- mean((yvecValidation - lassoYhat)^2)
  
  
lassoRMSE <- sqrt(lassoMSE)

lassoRMSE
```

When using 10-fold cross validation to determine the most optimal value of lamda for LASSO regression to predict player salaries in 1987 using selected variables, the average difference between our predicted values and actual values is roughly $310,172 (RMSE converted to thousands of dollars).


h. If you were to perform backward elimination for selecting the "best" subset of predictors for predicting salary, which variables would remain in the model?

```{r}

regTrain <- MLB2[trainInd, ]
regVal <- MLB2[-trainInd, ]
#Build Intercept Only Model. NOTE: ~ 1 tells R that you only want an intercept
int_only_model <- lm(Salary ~ 1, 
                      data = regTrain)

#Build model with all potential regressors. 

full_model <- lm(Salary ~ ., 
                  data = regTrain)

#Perform backward elimination (variables taken away) using base-R
#Have R do it all
stepwise_model <- step(full_model, 
                       scope = list(lower = int_only_model, upper = full_model), 
                       direction = "backward")
summary(stepwise_model)
```

Using backwards stepwise elimination, we find that none of the variables are removed in the best model.

i. Based on the RMSE for the validation data, which model (the model selected by LASSO regression with $\lambda$ based on the minimum MSE OR the model selected by backward elimination) produced a better RMSE on the validation data? Justify your answer. (Your answer should include the value of the RMSE for both models.)

```{r}


stepPredict <- predict(stepwise_model, newdata = regVal)

stepRMSE <- sqrt(mean((regVal$Salary-stepPredict)^2))

lassoRMSE
stepRMSE



```

RMSE values 
* LASSO-CV:
  + **310.1718**
* stepwise:
  + 311.0321

Based on our results, we can conclude that the 10-fold cross validation to find an optimal lambda value for LASSO regression was better at lowering the average difference in predicted player salary in 1987 when compared to their actual salaries. Although the results are close, the LASSO model fits the data better and contains more precise predictions than the stepwise model.
